Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.1"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.1"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/var/lib/slurm/slurmd/job12241415/slurm_script: line 12: activate: No such file or directory
[NbConvertApp] Converting notebook try_jupy.ipynb to notebook
Traceback (most recent call last):
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/bin/jupyter-nbconvert", line 10, in <module>
    sys.exit(main())
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/jupyter_core/application.py", line 269, in launch_instance
    return super().launch_instance(argv=argv, **kwargs)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 103, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 124, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbclient/util.py", line 85, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbclient/util.py", line 60, in just_run
    return loop.run_until_complete(coro)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbclient/client.py", line 1019, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/nbclient/client.py", line 913, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Custom dataset class
class CustomMNIST(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.images = []
        self.labels = []

        # Load images and labels from the directory
        for label in os.listdir(data_dir):
            label_dir = os.path.join(data_dir, label)
            if os.path.isdir(label_dir):
                for img_file in os.listdir(label_dir):
                    img_path = os.path.join(label_dir, img_file)
                    self.images.append(img_path)
                    self.labels.append(int(label[-1]))  # Extract label from folder name

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('L')  # Convert to grayscale
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

# Define the transformations (including normalization)
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize to fit CLIP model requirements
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
])

# Load the custom dataset using DataLoader
train_dataset = CustomMNIST(data_dir='./data/train', transform=transform)
test_dataset = CustomMNIST(data_dir='./data/test', transform=transform)

train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)

# Visualize a single image with its label from the DataLoader
def plot_image(image, label):
    plt.figure(figsize=(6, 6))
    plt.imshow(image.numpy().squeeze(), cmap='gray')  # Convert tensor to NumPy and remove channel
    plt.title(f'Label: {label}')  # Show the label
    plt.axis('off')
    plt.tight_layout()
    plt.show()

# Load the CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Example: Get a batch of images and labels from the train_loader
for images, labels in train_loader:
    # Plot the first image from the current batch
    plot_image(images[0], labels[0])  # Display the first image and its corresponding label
    
    # Preprocess the image for CLIP (no need to apply transforms again)
    img_for_clip = images[0].unsqueeze(0).to(device)  # Add batch dimension and move to device
    
    # Encode the image using CLIP
    with torch.no_grad():
        image_features = model.encode_image(img_for_clip)

    print("Image Features Shape:", image_features.shape)
    print("Image Features:", image_features)

    # Test with dummy text
    text = clip.tokenize(["a photo of a handwritten digit"]).to(device)

    # Encode the text
    with torch.no_grad():
        text_features = model.encode_text(text)

    print("Text Features Shape:", text_features.shape)
    print("Text Features:", text_features)

    break  # Exit after the first batch to avoid too much output
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
Cell [0;32mIn[6], line 56[0m
[1;32m     54[0m [38;5;66;03m# Load the CLIP model[39;00m
[1;32m     55[0m device [38;5;241m=[39m [38;5;124m"[39m[38;5;124mcuda[39m[38;5;124m"[39m [38;5;28;01mif[39;00m torch[38;5;241m.[39mcuda[38;5;241m.[39mis_available() [38;5;28;01melse[39;00m [38;5;124m"[39m[38;5;124mcpu[39m[38;5;124m"[39m
[0;32m---> 56[0m model, preprocess [38;5;241m=[39m [43mclip[49m[38;5;241;43m.[39;49m[43mload[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mViT-B/32[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[43mdevice[49m[38;5;241;43m=[39;49m[43mdevice[49m[43m)[49m
[1;32m     58[0m [38;5;66;03m# Example: Get a batch of images and labels from the train_loader[39;00m
[1;32m     59[0m [38;5;28;01mfor[39;00m images, labels [38;5;129;01min[39;00m train_loader:
[1;32m     60[0m     [38;5;66;03m# Plot the first image from the current batch[39;00m

File [0;32m/proj/sciml/users/x_stear/playground/./CLIP/clip/clip.py:133[0m, in [0;36mload[0;34m(name, device, jit)[0m
[1;32m    130[0m             [38;5;28;01mif[39;00m [38;5;124m"[39m[38;5;124mvalue[39m[38;5;124m"[39m [38;5;129;01min[39;00m node[38;5;241m.[39mattributeNames() [38;5;129;01mand[39;00m [38;5;28mstr[39m(node[[38;5;124m"[39m[38;5;124mvalue[39m[38;5;124m"[39m])[38;5;241m.[39mstartswith([38;5;124m"[39m[38;5;124mcuda[39m[38;5;124m"[39m):
[1;32m    131[0m                 node[38;5;241m.[39mcopyAttributes(device_node)
[0;32m--> 133[0m [43mmodel[49m[38;5;241;43m.[39;49m[43mapply[49m[43m([49m[43mpatch_device[49m[43m)[49m
[1;32m    134[0m patch_device(model[38;5;241m.[39mencode_image)
[1;32m    135[0m patch_device(model[38;5;241m.[39mencode_text)

File [0;32m/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/torch/nn/modules/module.py:895[0m, in [0;36mModule.apply[0;34m(self, fn)[0m
[1;32m    859[0m [38;5;250m[39m[38;5;124mr[39m[38;5;124;03m"""Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.[39;00m
[1;32m    860[0m 
[1;32m    861[0m [38;5;124;03mTypical use includes initializing the parameters of a model[39;00m
[0;32m   (...)[0m
[1;32m    892[0m 
[1;32m    893[0m [38;5;124;03m"""[39;00m
[1;32m    894[0m [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 895[0m     [43mmodule[49m[38;5;241;43m.[39;49m[43mapply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    896[0m fn([38;5;28mself[39m)
[1;32m    897[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m

File [0;32m/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/torch/nn/modules/module.py:895[0m, in [0;36mModule.apply[0;34m(self, fn)[0m
[1;32m    859[0m [38;5;250m[39m[38;5;124mr[39m[38;5;124;03m"""Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.[39;00m
[1;32m    860[0m 
[1;32m    861[0m [38;5;124;03mTypical use includes initializing the parameters of a model[39;00m
[0;32m   (...)[0m
[1;32m    892[0m 
[1;32m    893[0m [38;5;124;03m"""[39;00m
[1;32m    894[0m [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 895[0m     [43mmodule[49m[38;5;241;43m.[39;49m[43mapply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    896[0m fn([38;5;28mself[39m)
[1;32m    897[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m

File [0;32m/proj/sciml/users/x_stear/ProbVML/ProbVLM/prob/lib/python3.8/site-packages/torch/nn/modules/module.py:896[0m, in [0;36mModule.apply[0;34m(self, fn)[0m
[1;32m    894[0m [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[1;32m    895[0m     module[38;5;241m.[39mapply(fn)
[0;32m--> 896[0m [43mfn[49m[43m([49m[38;5;28;43mself[39;49m[43m)[49m
[1;32m    897[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m

File [0;32m/proj/sciml/users/x_stear/playground/./CLIP/clip/clip.py:130[0m, in [0;36mload.<locals>.patch_device[0;34m(module)[0m
[1;32m    128[0m [38;5;28;01mfor[39;00m graph [38;5;129;01min[39;00m graphs:
[1;32m    129[0m     [38;5;28;01mfor[39;00m node [38;5;129;01min[39;00m graph[38;5;241m.[39mfindAllNodes([38;5;124m"[39m[38;5;124mprim::Constant[39m[38;5;124m"[39m):
[0;32m--> 130[0m         [38;5;28;01mif[39;00m [38;5;124m"[39m[38;5;124mvalue[39m[38;5;124m"[39m [38;5;129;01min[39;00m node[38;5;241m.[39mattributeNames() [38;5;129;01mand[39;00m [38;5;28mstr[39m([43mnode[49m[43m[[49m[38;5;124;43m"[39;49m[38;5;124;43mvalue[39;49m[38;5;124;43m"[39;49m[43m][49m)[38;5;241m.[39mstartswith([38;5;124m"[39m[38;5;124mcuda[39m[38;5;124m"[39m):
[1;32m    131[0m             node[38;5;241m.[39mcopyAttributes(device_node)

[0;31mTypeError[0m: 'torch._C.Node' object is not subscriptable
TypeError: 'torch._C.Node' object is not subscriptable

